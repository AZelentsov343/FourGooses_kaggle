{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import codecs\n",
    "from lxml import etree, html as lhtml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import os\n",
    "import string\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 29s, sys: 5min 7s, total: 16min 36s\n",
      "Wall time: 11min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_page_text(filename):\n",
    "    with codecs.open(path + filename, 'r', 'utf-8') as f:\n",
    "        url = f.readline().strip()\n",
    "        soup = BeautifulSoup(f, 'lxml')\n",
    "        title = soup.title.text\n",
    "        text = soup.get_text()\n",
    "        return text\n",
    "\n",
    "        \n",
    "def get_title(filename):\n",
    "    with codecs.open(path + filename, 'r', 'utf-8') as f:\n",
    "        url = f.readline().strip()\n",
    "        soup = BeautifulSoup(f, 'lxml')\n",
    "        title = soup.title.text\n",
    "        return title\n",
    "\n",
    "    \n",
    "def get_texts_and_titles_one_thread(filenames):\n",
    "    texts, titles = [], []\n",
    "    for i in range(1, n + 1):\n",
    "        filename = str(i) + '.dat'\n",
    "        try:\n",
    "            with codecs.open(path + filename, 'r', 'utf-8') as f:\n",
    "                url = f.readline().strip()\n",
    "                soup = BeautifulSoup(f, 'lxml')\n",
    "                title = soup.title.text\n",
    "                text = soup.get_text()\n",
    "                texts.append(text)\n",
    "                titles.append(title)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return texts, titles\n",
    "\n",
    "\n",
    "path = 'content/'\n",
    "filenames = os.listdir(path)\n",
    "titles = []\n",
    "texts = []\n",
    "n = 1000\n",
    "# n - число файлов, которые будут прочитаны: 1.dat, 2.dat, ..., n.dat\n",
    "# n_max = 28026\n",
    "\n",
    "with ThreadPool(10) as pool:\n",
    "    texts = list(pool.map(get_page_text, filenames[0:1001]))\n",
    "pool.join()\n",
    "\n",
    "with ThreadPool(10) as pool:\n",
    "    titles = list(pool.map(get_title, filenames[0:1001]))\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 51min 49s, sys: 1min 25s, total: 1h 53min 15s\n",
      "Wall time: 1h 55min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def normalize(text):\n",
    "    punc = string.punctuation\n",
    "    punc += '/n/a/b/f/r/t/v'\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    text = ''.join([o if not o in punc else ' ' for o in text])\n",
    "    text = list(morph.parse(word)[0].normal_form for word in text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "with ThreadPool(10) as pool:\n",
    "    texts = list(pool.map(normalize, texts))\n",
    "pool.join()\n",
    "\n",
    "with ThreadPool(10) as pool:\n",
    "    titles = list(pool.map(normalize, titles))\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df = 0.03 max_df = 0.5 words_shape = 13165 title_words_shape = 3118\n",
      "CPU times: user 26 s, sys: 4.11 s, total: 30.1 s\n",
      "Wall time: 35.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def choose_min_max_df(texts_w_norm, titles_w_norm):\n",
    "    '''\n",
    "    choose min_df & max_df parameters for CountVectorizer, TfIdfVectorizer.\n",
    "    Isn't finished yet.\n",
    "    '''\n",
    "    \n",
    "    min_df_arr = [0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1]\n",
    "    max_df_arr = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    for min_df in min_df_arr:\n",
    "        for max_df in max_df_arr:\n",
    "            texts = [' '.join(text) for text in texts_w_norm]\n",
    "            vectorizer = CountVectorizer(min_df=min_df, max_df=max_df)\n",
    "            W = vectorizer.fit_transform(texts)\n",
    "            words = vectorizer.get_feature_names()\n",
    "\n",
    "            title_cntvect = CountVectorizer()\n",
    "            titles = [' '.join(title) for title in titles_w_norm]\n",
    "            title_W = title_cntvect.fit_transform(titles)\n",
    "            title_words = title_cntvect.get_feature_names()\n",
    "\n",
    "            print('min_df =', min_df, 'max_df =', max_df, \n",
    "                  'words_shape =', len(words), \n",
    "                  'title_words_shape =', len(title_words))\n",
    "            # print(title_words)\n",
    "            # print('\\n\\n', words, '\\n\\n')\n",
    "            \n",
    "            \n",
    "min_df, max_df = 0.002, 0.5\n",
    "texts = [' '.join(text) for text in texts]\n",
    "vectorizer = CountVectorizer(min_df=min_df, max_df=max_df)\n",
    "W = vectorizer.fit_transform(texts)\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "title_cntvect = CountVectorizer(min_df=min_df, max_df=max_df)\n",
    "titles = [' '.join(title) for title in titles]\n",
    "title_W = title_cntvect.fit_transform(titles)\n",
    "title_words = title_cntvect.get_feature_names()\n",
    "\n",
    "print('min_df =', min_df, 'max_df =', max_df, \n",
    "      'words_shape =', len(words), \n",
    "      'title_words_shape =', len(title_words))\n",
    "            # print(title_words)\n",
    "            # print('\\n\\n', words, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 312 ms, total: 23.4 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=min_df, max_df=max_df)\n",
    "\n",
    "texts_W_tfidf = tfidf.fit_transform(texts)\n",
    "titles_W_tfidf = tfidf.fit_transform(titles)\n",
    "texts_W_mat = texts_W_tfidf.todense()\n",
    "titles_W_mat = titles_W_tfidf.todense()\n",
    "\n",
    "texts_W_vocab = tfidf.get_feature_names()\n",
    "titles_W_vocab = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "\n",
    "def cos_dist(X):\n",
    "    return squareform(pdist(X, metric='cosine'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.56 s, sys: 31.2 ms, total: 1.59 s\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "titles_cdist = cos_dist(titles_W_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.64 s, sys: 0 ns, total: 9.64 s\n",
      "Wall time: 9.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.9861884 , 0.99633716, ..., 0.98831151, 0.98478626,\n",
       "        0.98684992],\n",
       "       [0.9861884 , 0.        , 0.89828601, ..., 0.91741135, 0.92501084,\n",
       "        0.96455643],\n",
       "       [0.99633716, 0.89828601, 0.        , ..., 0.93168234, 0.98316882,\n",
       "        0.98483372],\n",
       "       ...,\n",
       "       [0.98831151, 0.91741135, 0.93168234, ..., 0.        , 0.95407295,\n",
       "        0.89713327],\n",
       "       [0.98478626, 0.92501084, 0.98316882, ..., 0.95407295, 0.        ,\n",
       "        0.98311164],\n",
       "       [0.98684992, 0.96455643, 0.98483372, ..., 0.89713327, 0.98311164,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "texts_cdist = cos_dist(texts_W_mat)\n",
    "texts_cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_csv(texts_cdist, texts_W_mat):\n",
    "    pd.DataFrame(texts_cdist).to_csv('texts_cdist.csv')\n",
    "    pd.DataFrame(texts_W_mat).to_csv('texts_tfidf.csv')\n",
    "    \n",
    "\n",
    "def titles_to_csv(titles_cdist, titles_W_mat):\n",
    "    pd.DataFrame(titles_cdist).to_csv('titles_cdist.csv')\n",
    "    pd.DataFrame(titles_W_mat).to_csv('titles_tfidf.csv')\n",
    "    \n",
    "\n",
    "def get_from_csv(string):\n",
    "    if string == 'titles':\n",
    "        np_tfidf = np.array(pd.read_csv('titles_tfidf.csv'))\n",
    "        np_cdist = np.array(pd.read_csv('titles_cdist.csv'))\n",
    "    elif string == 'texts':\n",
    "        np_tfidf = np.array(pd.read_csv('titles_tfidf.csv'))\n",
    "        np_cdist = np.array(pd.read_csv('titles_cdist.csv'))\n",
    "    return np_tfidf, np_cdist\n",
    "\n",
    "\n",
    "test_title_idf, test_title_cdist = get_from_csv('titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [9.98000000e+02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 5.14251619e-01],\n",
       "       [9.99000000e+02, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+03, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_title_idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
